{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN61ZyJk+gtuyDY124/XOQj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharma-kshitij-ks/Empowering-Investors-Hackathon/blob/main/EmpoweredinvestorsFinalCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKGFj3wvydyW"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "import openai  # Import the OpenAI library\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"vader_lexicon\")\n",
        "\n",
        "# Initialize the Sentiment Intensity Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"Your_key\"  # Replace with your actual API key\n",
        "\n",
        "# Define the URL of the Yahoo Finance news section\n",
        "url = \"https://finance.yahoo.com/news\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Find all the news article elements on the page\n",
        "article_elements = soup.find_all(\"li\", class_=\"js-stream-content\")\n",
        "\n",
        "# Loop through the article elements and extract relevant information\n",
        "for article_element in article_elements:\n",
        "    article_title_element = article_element.find(\"h3\")\n",
        "    article_link_element = article_element.find(\"a\", class_=\"js-content-viewer\")\n",
        "\n",
        "    if article_title_element and article_link_element:\n",
        "        article_title = article_title_element.text.strip()\n",
        "        article_link = article_link_element.get(\"href\")\n",
        "\n",
        "        # Visit the article URL and scrape the content\n",
        "        article_url = f\"https://finance.yahoo.com{article_link}\"\n",
        "        article_response = requests.get(article_url)\n",
        "        article_soup = BeautifulSoup(article_response.content, \"html.parser\")\n",
        "\n",
        "        article_content_element = article_soup.find(\"div\", class_=\"caas-body\")\n",
        "        if article_content_element:\n",
        "            article_text = article_content_element.get_text()\n",
        "            sentences = sent_tokenize(article_text)\n",
        "\n",
        "            # Initialize sentiment scores for ensemble\n",
        "            total_sentiment_score = 0\n",
        "            total_sentences = len(sentences)\n",
        "\n",
        "            for sentence in sentences:\n",
        "                # Perform sentiment analysis using Sentiment Intensity Analyzer\n",
        "                sentiment_scores = sia.polarity_scores(sentence)\n",
        "                sentiment_score = sentiment_scores[\"compound\"]\n",
        "\n",
        "                # Add sentiment score to ensemble total\n",
        "                total_sentiment_score += sentiment_score\n",
        "\n",
        "            # Calculate average sentiment score for ensemble\n",
        "            average_sentiment_score = total_sentiment_score / total_sentences\n",
        "\n",
        "            # Classify sentiment label based on ensemble average score\n",
        "            if average_sentiment_score > 0.2:\n",
        "                sentiment_label = \"Genuine\"\n",
        "            elif average_sentiment_score < -0.2:\n",
        "                sentiment_label = \"Fake\"\n",
        "            else:\n",
        "                sentiment_label = \"Neutral\"\n",
        "\n",
        "            # Generate explanation using GPT\n",
        "            prompt = f\"Summarize why the news article titled '{article_title}' is {sentiment_label}.\"\n",
        "            explanation = openai.Completion.create(\n",
        "                engine=\"text-davinci-003\",\n",
        "                prompt=prompt,\n",
        "                max_tokens=100\n",
        "            )\n",
        "            explanation_text = explanation.choices[0].text.strip()\n",
        "\n",
        "            print(\"Title:\", article_title)\n",
        "            print(\"URL:\", article_url)\n",
        "            print(\"Sentiment Label:\", sentiment_label)\n",
        "            print(\"Average Sentiment Score:\", average_sentiment_score)\n",
        "            print(\"Explanation:\", explanation_text)\n",
        "            print(\"\\n\")"
      ]
    }
  ]
}